# -*- coding: utf-8 -*-
"""TCAS_final_epochs1200-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g_ifTqSZD3XIGWdJgTf-mOo_ks7REdQ-
"""

!pip install emoji
!pip install pythainlp
!pip install tensorflow deepcut
!pip install matplotlib==3.6.2

from google.colab import drive
drive.mount('/content/drive')

import os

import pandas as pd

TCAS61 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61.xlsx')
TCAS62 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62.xlsx')
TCAS63 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63.xlsx')
TCAS64 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas64.xlsx')
TCAS65 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65.xlsx')

y1_pos = round((len(TCAS61[TCAS61['label']=="pos"])/687) * 100,2)
y1_neg = round((len(TCAS61[TCAS61['label']=="neg"])/687)*100,2)
y2_pos = round((len(TCAS62[TCAS62['label']=="pos"])/221)*100,2)
y2_neg = round((len(TCAS62[TCAS62['label']=="neg"])/221)*100,2)
y3_pos = round((len(TCAS63[TCAS63['label']=="pos"])/235)*100,2)
y3_neg = round((len(TCAS63[TCAS63['label']=="neg"])/235)*100,2)
y4_pos = round((len(TCAS64[TCAS64['label']=="pos"])/138)*100,2)
y4_neg = round((len(TCAS64[TCAS64['label']=="neg"])/138)*100,2)
y5_pos = round((len(TCAS65[TCAS65['label']=="pos"])/93)*100,2)
y5_neg = round((len(TCAS65[TCAS65['label']=="neg"])/93)*100,2)

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS61','TCAS62','TCAS63','TCAS64','TCAS65']
Pos = [y1_pos, y2_pos, y3_pos,  y4_pos, y5_pos]
Neg = [y1_neg, y2_neg, y3_neg, y4_neg, y5_neg]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Pos, width, label='Positive')
rects2 = ax.bar(x + width/2, Neg, width, label='Negative')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Percent')
ax.set_title('Percent by Positive and Negative')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()

# Some data
Pos = [y1_pos, y2_pos, y3_pos,  y4_pos, y5_pos]
Neg = [y1_neg, y2_neg, y3_neg, y4_neg, y5_neg]
labels = ['Positive','Negative']

# Make figure and axes
fig, axs = plt.subplots(1,5)
fig.set_size_inches(20, 10)

# A standard pie plot
axs[0].pie((Pos[0],Neg[0]), labels=labels, autopct='%1.1f%%', shadow=True)
axs[1].pie((Pos[1],Neg[1]), labels=labels, autopct='%1.1f%%', shadow=True)
axs[2].pie((Pos[2],Neg[2]), labels=labels, autopct='%1.1f%%', shadow=True)
axs[3].pie((Pos[3],Neg[3]), labels=labels, autopct='%1.1f%%', shadow=True)
axs[4].pie((Pos[4],Neg[4]), labels=labels, autopct='%1.1f%%', shadow=True)

plt.show()

"""#Clean text
- ลบอักขระพิเศษ
- ลบอีโมจิ
- Custom Word
- split Word
- Counter word
"""

import string
remove = string.ascii_letters+string.punctuation+'&1234567890‘’'
remove

def clean1(input):
  for i in range(len(remove)):
    input['text'] = input['text'].str.replace(remove[i], '')
  input['text'] = input['text'].str.replace("\n", '')
  input['text'] = input['text'].str.replace("\u200b", '')

len(TCAS61),len(TCAS62),len(TCAS63),len(TCAS64),len(TCAS65)

dat = [TCAS61,TCAS62,TCAS63,TCAS64,TCAS65]
for data in dat:
  clean1(data)

import emoji
def clean_emoji(input):
  ct = 0
  for text in input['text']:
    clean_emo = emoji.replace_emoji(text)
    input['text'].loc[ct] = clean_emo
    ct += 1

for data in dat:
  clean_emoji(data)

#ลบคำซ้ำ ex. มากกกก = มาก
import pythainlp
def word_precess(s):
    c = ''
    flag = ''
    counter = 0
    for i, letter in enumerate(s):
        if letter == flag:
            counter += 1
            if counter > 2:
                continue  # start the loop from beginning
        else:
            flag = letter
            counter = 1
        c = c + letter

    return c
vowels = pythainlp.thai_above_vowels + pythainlp.thai_follow_vowels+ pythainlp.thai_punctuations +pythainlp.thai_signs

from pythainlp.tokenize import word_tokenize
from pythainlp.corpus import thai_stopwords

stopwords = list(thai_stopwords())

def split_clean(input):
  for i in range(len(input)):
    text = input['text'][i]
    split_word = word_tokenize(text, engine="deepcut", keep_whitespace=False)
    for j in range(len(split_word)):
      if split_word[j] != word_precess(split_word[j]):
        split_word[j] = word_precess(split_word[j])

    delc = 0
    for k in range(len(split_word)):
      if len(split_word[k-delc]) <= 1:
        split_word.remove(split_word[k-delc])
        delc += 1
      elif len(split_word[k-delc]) == 2 and split_word[k-delc][0] == split_word[k-delc][1] :
        split_word.remove(split_word[k-delc])
        delc += 1
      elif split_word[k-delc][0] in vowels:
        split_word[k-delc] = split_word[k-delc].replace(split_word[k-delc][0],"")
        delc += 1

    # list_word_not_stopwords = [k for k in split_word if k not in stopwords]

    input['text'].loc[i] = split_word

for data in dat:
  split_clean(data)

"""#Data preparation"""

frames = [ TCAS61, TCAS62, TCAS63, TCAS64, TCAS65 ]

df = pd.concat(frames) #รวมdataframe tcas61-tcas65 เข้าด้วยกัน

len(df)

df

df[df['label']=="neg"]

df[df['label']=="pos"]

"""Encode label"""

from sklearn.preprocessing import LabelEncoder
label = df['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((1371, 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

"""train test split 80:20"""

from sklearn.model_selection import train_test_split
sentences = df['text'].tolist()
sentences_train, sentences_test, y_train, y_test = train_test_split(
        sentences, y, test_size=0.2, random_state=15, shuffle=True)

""" texts to sequences"""

from keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)

x_train = tokenizer.texts_to_sequences(sentences_train)
x_test = tokenizer.texts_to_sequences(sentences_test)

vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index

print(sentences_train)
print(x_train)

vocab_size

lenDF = [] #หาประโยคที่ยาวที่สุด
for i in range(len(df)):
  lenDF.append(len(df.text.values[i]))
max(lenDF)

from keras_preprocessing.sequence import pad_sequences

maxlen = max(lenDF)

x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)
x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)

print(x_train[2, :])

"""#CNN model"""

epochs = 1500
from tensorflow.keras.optimizers import Adam
adam = Adam(learning_rate=0.0001)

from keras.models import Sequential
from keras import layers
from keras import regularizers
from keras.layers import GaussianNoise
from tensorflow.python.keras.layers.recurrent import LSTM

embedding_dim = 128
model = Sequential()
model.add(layers.Embedding(input_dim=vocab_size, 
                           output_dim=embedding_dim, 
                           input_length=maxlen,trainable=False))#,trainable=False
model.add(layers.Dropout(0.5))
model.add(layers.Conv1D(128,5,activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.GlobalMaxPool1D())
model.add(layers.Dropout(0.5))
model.add(layers.Flatten())
model.add(layers.Dropout(0.3))
model.add(layers.Dense(2, activation='softmax'))
model.compile(optimizer=adam,
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.summary()

history = model.fit(x_train, y_train,
                    epochs=epochs ,
                    verbose=True,
                    validation_data=(x_test, y_test),
                    batch_size=32,
                    shuffle=True) #callbacks = [callbacks_list],

import matplotlib.pyplot as plt
plt.style.use('ggplot')

def plot_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    x = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(x, acc, 'b', label='Training acc')
    plt.plot(x, val_acc, 'r', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(x, loss, 'b', label='Training loss')
    plt.plot(x, val_loss, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

from matplotlib.pyplot import *
loss, accuracy = model.evaluate(x_train, y_train, verbose=False)
print("Training Accuracy: {:.4f}".format(accuracy))
loss, accuracy = model.evaluate(x_test, y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(max(history.history['val_accuracy'])))
plot_history(history)

from sklearn.metrics import confusion_matrix
import seaborn as sn
from sklearn.metrics import classification_report
import plotly.figure_factory as ff

category = df['label'].tolist()
unique_category = list(set(category))
num_classes = len(unique_category)
output_tokenizer  = Tokenizer()
output_tokenizer .fit_on_texts(unique_category)

label_dict = output_tokenizer.word_index
label = [key for key, value in label_dict.items()]

predicted_classes = np.argmax(model.predict(x_test), axis=-1)
predicted_classes.shape


y_true = np.argmax(y_test,axis = 1)
print(y_test[0])
print(y_true[0])
cm = confusion_matrix(y_true, predicted_classes)
cm

print(classification_report(y_true, predicted_classes, target_names=label, digits=4))

"""#รอบTcas ในแต่ละรอบ (non-label)"""

TCAS61_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_1.xlsx')
TCAS61_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_2.xlsx')
TCAS61_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_3.xlsx')
TCAS61_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_4.xlsx')
TCAS61_5 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_5.xlsx')

TCAS62_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_1R.xlsx')
TCAS62_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_2R.xlsx')
TCAS62_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_3R.xlsx')
TCAS62_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_4R.xlsx')
TCAS62_5 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_5R.xlsx')

TCAS63_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_1R.xlsx')
TCAS63_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_2R.xlsx')
TCAS63_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_3R.xlsx')
TCAS63_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_4R.xlsx')
#TCAS63_5

#TCAS64_1
TCAS64_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas64_2R.xlsx')
TCAS64_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas64_3R.xlsx')
#TCAS64_4

TCAS65_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_1.xlsx')
TCAS65_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_2.xlsx')
TCAS65_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_3.xlsx')
#TCAS65_4

#clean text tcas61
dat61 = [TCAS61_1,TCAS61_2,TCAS61_3,TCAS61_4,TCAS61_5]
for data in dat61:
  clean1(data)
for data in dat61:
 clean_emoji(data)
for data in dat61:
 split_clean(data)
 
 #clean text tcas62
dat62 = [TCAS62_1,TCAS62_2,TCAS62_3,TCAS62_4,TCAS62_5]
for data in dat62:
  clean1(data)
for data in dat62:
 clean_emoji(data)
for data in dat62:
 split_clean(data)

 #clean text tcas63
dat63 = [TCAS63_1,TCAS63_2,TCAS63_3,TCAS63_4]
for data in dat63:
  clean1(data)
for data in dat63:
 clean_emoji(data)
for data in dat63:
 split_clean(data)

 #clean text tcas64
dat64 = [TCAS64_2,TCAS64_3]
for data in dat64:
  clean1(data)
for data in dat64:
 clean_emoji(data)
for data in dat64:
 split_clean(data)

 #clean text tcas65
dat65 = [TCAS65_1,TCAS65_2,TCAS65_3]
for data in dat65:
  clean1(data)
for data in dat65:
 clean_emoji(data)
for data in dat65:
 split_clean(data)

frames = [ TCAS61_1]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes61_1 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes61_1.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes61_1)
print("TCAS61 รอบ 1 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS61_2]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes61_2 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes61_2.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes61_2)
print("TCAS61 รอบ 2")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS61_3]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes61_3 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes61_3.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes61_3)
print("TCAS61 รอบ 3 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS61_4]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes61_4 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes61_4.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes61_4)
print("TCAS61 รอบ 4 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS61_5]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes61_5 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes61_5.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes61_5)
print("TCAS61 รอบ 5 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS62_1]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes62_1 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes62_1.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes62_1)
print("TCAS62 รอบ 1 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS62_2]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes62_2 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes62_2.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes62_2)
print("TCAS62 รอบ 2 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS62_3]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes62_3 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes62_3.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes62_3)
print("TCAS62 รอบ 3 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS62_4]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes62_4 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes62_4.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes62_4)
print("TCAS62 รอบ 4 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS62_5]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes62_5 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes62_5.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes62_5)
print("TCAS62 รอบ 5 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS63_1]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes63_1 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes63_1.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes63_1)
print("TCAS63 รอบ 1 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS63_2]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes63_2 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes63_2.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes63_2)
print("TCAS63 รอบ 2 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS63_3]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes63_3 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes63_3.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes63_3)
print("TCAS63 รอบ 3 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS63_4]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes63_4 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes63_4.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes63_4)
print("TCAS63 รอบ 4 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS64_2]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes64_2 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes64_2.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes64_2)
print("TCAS64 รอบ 2 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS64_3]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes64_3 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes64_3.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes64_3)
print("TCAS64 รอบ 3 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS65_1]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes65_1 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes65_1.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes65_1)
print("TCAS65 รอบ 1 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS65_2]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes65_2 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes65_2.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes65_2)
print("TCAS65 รอบ 2 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

frames = [ TCAS65_3]

df_test = pd.concat(frames)

sentences_train = df_test['text'].tolist()
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
test_xA = tokenizer.texts_to_sequences(sentences_train)

from keras_preprocessing.sequence import pad_sequences

maxlen = 77

test_xA = pad_sequences(test_xA, padding='post', maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder
label = df_test['label']
encoder = LabelEncoder()
Labels = encoder.fit_transform(label)
Labels[0:50]

encoder = OneHotEncoder(sparse=False)
novels_labels = Labels.reshape((len(df_test), 1))
y=encoder.fit_transform(novels_labels)
y[0:5]

predicted_classes65_3 = np.argmax(model.predict(test_xA), axis=-1)
predicted_classes65_3.shape

y_true = np.argmax(y,axis = 1)
cm = confusion_matrix(y_true, predicted_classes65_3)
print("TCAS65 รอบ 3 ")

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print("Accuracy :",round((cm[1][0] + cm[0][1])/ (cm[1][0] + cm[0][1] + cm[0][0] + cm[1][1]),4),"%")

#Counter word
from collections import Counter
#tcas61
tcas61_1_count= []
for i in range(len(TCAS61_1)):
  tcas61_1_count += TCAS61_1['text'][i] 

print((Counter(tcas61_1_count)))

tcas61_2_count= []
for i in range(len(TCAS61_2)):
  tcas61_2_count += TCAS61_2['text'][i] 

print((Counter(tcas61_2_count)))

tcas61_3_count= []
for i in range(len(TCAS61_3)):
  tcas61_3_count += TCAS61_3['text'][i] 

print((Counter(tcas61_3_count)))

tcas61_4_count= []
for i in range(len(TCAS61_4)):
  tcas61_4_count += TCAS61_4['text'][i] 

print((Counter(tcas61_4_count)))

tcas61_5_count= []
for i in range(len(TCAS61_5)):
  tcas61_5_count += TCAS61_5['text'][i] 

print((Counter(tcas61_5_count)))

#tcas62
tcas62_1_count= []
for i in range(len(TCAS62_1)):
  tcas62_1_count += TCAS62_1['text'][i] 

print((Counter(tcas62_1_count)))

tcas62_2_count= []
for i in range(len(TCAS62_2)):
  tcas62_2_count += TCAS62_2['text'][i] 

print((Counter(tcas62_2_count)))

tcas62_3_count= []
for i in range(len(TCAS62_3)):
  tcas62_3_count += TCAS62_3['text'][i] 

print((Counter(tcas62_3_count)))

tcas62_4_count= []
for i in range(len(TCAS62_4)):
  tcas62_4_count += TCAS62_4['text'][i] 

print((Counter(tcas62_4_count)))

tcas62_5_count= []
for i in range(len(TCAS62_5)):
  tcas62_5_count += TCAS62_5['text'][i] 

print((Counter(tcas62_5_count)))

#tcas63
tcas63_1_count= []
for i in range(len(TCAS63_1)):
  tcas63_1_count += TCAS63_1['text'][i] 

print((Counter(tcas63_1_count)))


tcas63_2_count= []
for i in range(len(TCAS63_2)):
  tcas63_2_count += TCAS63_2['text'][i] 

print((Counter(tcas63_2_count)))

tcas63_3_count= []
for i in range(len(TCAS63_3)):
  tcas63_3_count += TCAS63_3['text'][i] 

print((Counter(tcas63_3_count)))

tcas63_4_count= []
for i in range(len(TCAS63_4)):
  tcas63_4_count += TCAS63_4['text'][i] 

print((Counter(tcas63_4_count)))

#tcas64

tcas64_2_count= []
for i in range(len(TCAS64_2)):
  tcas64_2_count += TCAS64_2['text'][i] 

print((Counter(tcas64_2_count)))

tcas64_3_count= []
for i in range(len(TCAS64_3)):
  tcas64_3_count += TCAS64_3['text'][i] 

print((Counter(tcas64_3_count)))

#tcas65
tcas65_1_count= []
for i in range(len(TCAS65_1)):
  tcas65_1_count += TCAS65_1['text'][i] 

print((Counter(tcas65_1_count)))

tcas65_2_count= []
for i in range(len(TCAS65_2)):
  tcas65_2_count += TCAS65_2['text'][i] 

print((Counter(tcas65_2_count)))

tcas65_3_count= []
for i in range(len(TCAS65_3)):
  tcas65_3_count += TCAS65_3['text'][i] 

print((Counter(tcas65_3_count)))

"""Call sentens By highest frequency

"""

CALL61_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_1.xlsx')
CALL61_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_2.xlsx')
CALL61_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_3.xlsx')
CALL61_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_4.xlsx')
CALL61_5 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas61_5.xlsx')

CALL62_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_1R.xlsx')
CALL62_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_2R.xlsx')
CALL62_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_3R.xlsx')
CALL62_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_4R.xlsx')
CALL62_5 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas62_5R.xlsx')

CALL63_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_1R.xlsx')
CALL63_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_2R.xlsx')
CALL63_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_3R.xlsx')
CALL63_4 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas63_4R.xlsx')
#CALL63_5

#CALL64_1
CALL64_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas64_2R.xlsx')
CALL64_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas64_3R.xlsx')
#CALL64_4

CALL65_1 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_1.xlsx')
CALL65_2 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_2.xlsx')
CALL65_3 = pd.read_excel('/content/drive/MyDrive/TCAS/tcas65_3.xlsx')
#CALL65_4

Adat61 = [CALL61_1,CALL61_2,CALL61_3,CALL61_4,CALL61_5]
for data in Adat61:
  clean1(data)
for data in Adat61:
  clean_emoji(data)

Adat62 = [CALL62_1,CALL62_2,CALL62_3,CALL62_4,CALL62_5]
for data in Adat62:
  clean1(data)
for data in Adat62:
  clean_emoji(data)

Adat63 = [CALL63_1,CALL63_2,CALL63_3,CALL63_4]
for data in Adat63:
  clean1(data)
for data in Adat63:
  clean_emoji(data)

Adat64 = [CALL64_2,CALL64_3]
for data in Adat64:
  clean1(data)
for data in Adat64:
  clean_emoji(data)

Adat65 = [CALL65_1,CALL65_2,CALL65_3]
for data in Adat65:
  clean1(data)
for data in Adat65:
  clean_emoji(data)

#Top 2 tcas61
Word_Cas61_1 = ["ระบบ","สอบ"]
Word_Cas61_2 = ["คะแนน"]
Word_Cas61_3 = ["ติด","ระบบ"]
Word_Cas61_4 = ["รอบ","ติด","สมัคร","อันดับ"]
Word_Cas61_5 = ["ติด","เรียน"]

#Top 2 tcas62
Word_Cas62_1 = ["ระบบ","สมัคร","ทะเบียน","รหัส"]
Word_Cas62_2 = ["วัดสิงห์"]
Word_Cas62_3 = ["ติด"]
Word_Cas62_4 = ["รอบ","ติด","สมัคร","อันดับ"]
Word_Cas62_5 = ["ติด"]

#Top 2 tcas63
Word_Cas63_1 = ["เรียน"]
Word_Cas63_2 = ["คะแนน","สอบ"]
Word_Cas63_3 = ["รอบ"]
Word_Cas63_4 = ["รอบ","ติด"]

#Top 2 tcas64
Word_Cas64_2 = ["สอบ"]
Word_Cas64_3 = ["ทปอ"]

#Top 2 tcas65
Word_Cas65_1 = ["สอบ"]
Word_Cas65_2 = ["เรียน"]
Word_Cas65_3 = ["ติด"]

call_text64_3 = call_word(CALL64_3,Word_Cas64_3)
for text in call_text64_3:
  print(text)

"""Data preparation
- dataframe to list
- text to sequences

#tcas61
"""

#tcas61 รอบที่1
listtcas61_1=CALL61_1['text'].tolist()
tcas61_1=TCAS61_1['text'].tolist()
x_test61_1 = tokenizer.texts_to_sequences(tcas61_1)
x_test61_1 = pad_sequences(x_test61_1, padding='post', maxlen=maxlen)

#tcas61 รอบที่2
listtcas61_2=CALL61_2['text'].tolist()
tcas61_2=TCAS61_2['text'].tolist()
x_test61_2 = tokenizer.texts_to_sequences(tcas61_2)
x_test61_2 = pad_sequences(x_test61_2, padding='post', maxlen=maxlen)

#tcas61 รอบที่3
listtcas61_3 = CALL61_3['text'].tolist()
tcas61_3 = TCAS61_3['text'].tolist()
x_test61_3 = tokenizer.texts_to_sequences(tcas61_3)
x_test61_3 = pad_sequences(x_test61_3, padding='post', maxlen=maxlen)

#tcas61 รอบที่4
listtcas61_4 = CALL61_4['text'].tolist()
tcas61_4 = TCAS61_4['text'].tolist()
x_test61_4 = tokenizer.texts_to_sequences(tcas61_4)
x_test61_4 = pad_sequences(x_test61_4, padding='post', maxlen=maxlen)

#tcas61 รอบที่5
listtcas61_5 = CALL61_5['text'].tolist()
tcas61_5 = TCAS61_5['text'].tolist()
x_test61_5 = tokenizer.texts_to_sequences(tcas61_5)
x_test61_5 = pad_sequences(x_test61_5, padding='post', maxlen=maxlen)

predicted_classes61_1 = (model.predict(x_test61_1, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes61_2 = (model.predict(x_test61_2, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes61_3 = (model.predict(x_test61_3, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes61_4 = (model.predict(x_test61_4, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes61_5 = (model.predict(x_test61_5, verbose=1) > 0.5).astype("int32")[:,1]

for i in range(len(x_test61_1)):
 print("tcas61 รอบที่ 1 = %s, Predicted=%s" % (listtcas61_1[i], predicted_classes61_1[i]))

for i in range(len(x_test61_2)):
 print("tcas61 รอบที่ 2 =%s, Predicted=%s" % (listtcas61_2[i], predicted_classes61_2[i]))

for i in range(len(x_test61_3)):
 print("tcas61 รอบที่ 3 =%s, Predicted=%s" % (listtcas61_3[i], predicted_classes61_3[i]))

for i in range(len(x_test61_4)):
 print("tcas61 รอบที่ 4 =%s, Predicted=%s" % (listtcas61_4[i], predicted_classes61_4[i]))

for i in range(len(x_test61_5)):
 print("tcas61 รอบที่ 5 =%s, Predicted=%s" % (listtcas61_5[i], predicted_classes61_5[i]))

"""#tcas62"""

#tcas62 รอบที่1
listtcas62_1=CALL62_1['text'].tolist()
tcas62_1=TCAS62_1['text'].tolist()
x_test62_1 = tokenizer.texts_to_sequences(tcas62_1)
x_test62_1 = pad_sequences(x_test62_1, padding='post', maxlen=maxlen)

#tcas62 รอบที่2
listtcas62_2=CALL62_2['text'].tolist()
tcas62_2=TCAS62_2['text'].tolist()
x_test62_2 = tokenizer.texts_to_sequences(tcas62_2)
x_test62_2 = pad_sequences(x_test62_2, padding='post', maxlen=maxlen)

#tcas62 รอบที่3
listtcas62_3 = CALL62_3['text'].tolist()
tcas62_3 = TCAS62_3['text'].tolist()
x_test62_3 = tokenizer.texts_to_sequences(tcas62_3)
x_test62_3 = pad_sequences(x_test62_3, padding='post', maxlen=maxlen)

#tcas62 รอบที่4
listtcas62_4 = CALL62_4['text'].tolist()
tcas62_4 = TCAS62_4['text'].tolist()
x_test62_4 = tokenizer.texts_to_sequences(tcas62_4)
x_test62_4 = pad_sequences(x_test62_4, padding='post', maxlen=maxlen)

#tcas62 รอบที่5
listtcas62_5 = CALL62_5['text'].tolist()
tcas62_5 = TCAS62_5['text'].tolist()
x_test62_5 = tokenizer.texts_to_sequences(tcas62_5)
x_test62_5 = pad_sequences(x_test62_5, padding='post', maxlen=maxlen)

predicted_classes62_1 = (model.predict(x_test62_1, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes62_2 = (model.predict(x_test62_2, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes62_3 = (model.predict(x_test62_3, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes62_4 = (model.predict(x_test62_4, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes62_5 = (model.predict(x_test62_5, verbose=1) > 0.5).astype("int32")[:,1]

for i in range(len(x_test62_1)):
 print("tcas62 รอบที่ 1 = %s, Predicted=%s" % (listtcas62_1[i], predicted_classes62_1[i]))

for i in range(len(x_test62_2)):
 print("tcas62 รอบที่ 2 = %s, Predicted=%s" % (listtcas62_2[i], predicted_classes62_2[i]))

for i in range(len(x_test62_3)):
 print("tcas62 รอบที่ 3 =%s, Predicted=%s" % (listtcas62_3[i], predicted_classes62_3[i]))

for i in range(len(x_test62_4)):
 print("tcas62 รอบที่ 4 =%s, Predicted=%s" % (listtcas62_4[i], predicted_classes62_4[i]))

for i in range(len(x_test62_5)):
 print("tcas62 รอบที่ 5 =%s, Predicted=%s" % (listtcas62_5[i], predicted_classes62_5[i]))

"""#tcas63"""

#tcas63 รอบที่1
listtcas63_1=CALL63_1['text'].tolist()
tcas63_1=TCAS63_1['text'].tolist()
x_test63_1 = tokenizer.texts_to_sequences(tcas63_1)
x_test63_1 = pad_sequences(x_test63_1, padding='post', maxlen=maxlen)

#tcas63 รอบที่2
listtcas63_2=CALL63_2['text'].tolist()
tcas63_2=TCAS63_2['text'].tolist()
x_test63_2 = tokenizer.texts_to_sequences(tcas63_2)
x_test63_2 = pad_sequences(x_test63_2, padding='post', maxlen=maxlen)

#tcas63 รอบที่3
listtcas63_3 = CALL63_3['text'].tolist()
tcas63_3 = TCAS63_3['text'].tolist()
x_test63_3 = tokenizer.texts_to_sequences(tcas63_3)
x_test63_3 = pad_sequences(x_test63_3, padding='post', maxlen=maxlen)

#tcas63 รอบที่4
listtcas63_4 = CALL63_4['text'].tolist()
tcas63_4 = TCAS63_4['text'].tolist()
x_test63_4 = tokenizer.texts_to_sequences(tcas63_4)
x_test63_4 = pad_sequences(x_test63_4, padding='post', maxlen=maxlen)

predicted_classes63_1 = (model.predict(x_test63_1, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes63_2 = (model.predict(x_test63_2, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes63_3 = (model.predict(x_test63_3, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes63_4 = (model.predict(x_test63_4, verbose=1) > 0.5).astype("int32")[:,1]

for i in range(len(x_test63_1)):
 print("tcas63 รอบที่ 1 =%s, Predicted=%s" % (listtcas63_1[i], predicted_classes63_1[i]))

for i in range(len(x_test63_2)):
 print("tcas63 รอบที่ 2 =%s, Predicted=%s" % (listtcas63_2[i], predicted_classes63_2[i]))

for i in range(len(x_test63_3)):
 print("tcas63 รอบที่ 3 =%s, Predicted=%s" % (listtcas63_3[i], predicted_classes63_3[i]))

for i in range(len(x_test63_4)):
 print("tcas63 รอบที่ 4 =%s, Predicted=%s" % (listtcas63_4[i], predicted_classes63_4[i]))

"""#tcas64"""

#tcas64 รอบที่2
listtcas64_2=CALL64_2['text'].tolist()
tcas64_2=TCAS64_2['text'].tolist()
x_test64_2 = tokenizer.texts_to_sequences(tcas64_2)
x_test64_2 = pad_sequences(x_test64_2, padding='post', maxlen=maxlen)

#tcas64 รอบที่3
listtcas64_3 = CALL64_3['text'].tolist()
tcas64_3 = TCAS64_3['text'].tolist()
x_test64_3 = tokenizer.texts_to_sequences(tcas64_3)
x_test64_3 = pad_sequences(x_test64_3, padding='post', maxlen=maxlen)

predicted_classes64_2 = (model.predict(x_test64_2, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes64_3 = (model.predict(x_test64_3, verbose=1) > 0.5).astype("int32")[:,1]

for i in range(len(x_test64_2)):
 print("tcas64 รอบที่ 2 =%s, Predicted=%s" % (listtcas64_2[i], predicted_classes64_2[i]))

for i in range(len(x_test64_3)):
 print("tcas64 รอบที่ 3 =%s, Predicted=%s" % (listtcas64_3[i], predicted_classes64_3[i]))

"""#tcas65"""

#tcas65 รอบที่1
listtcas65_1=CALL65_1['text'].tolist()
tcas65_1=TCAS65_1['text'].tolist()
x_test65_1 = tokenizer.texts_to_sequences(tcas65_1)
x_test65_1 = pad_sequences(x_test65_1, padding='post', maxlen=maxlen)

#tcas63 รอบที่2
listtcas65_2=CALL65_2['text'].tolist()
tcas65_2=TCAS65_2['text'].tolist()
x_test65_2 = tokenizer.texts_to_sequences(tcas65_2)
x_test65_2 = pad_sequences(x_test65_2, padding='post', maxlen=maxlen)

#tcas65 รอบที่3
listtcas65_3 = CALL65_3['text'].tolist()
tcas65_3 = TCAS65_3['text'].tolist()
x_test65_3 = tokenizer.texts_to_sequences(tcas65_3)
x_test65_3 = pad_sequences(x_test65_3, padding='post', maxlen=maxlen)

predicted_classes65_1 = (model.predict(x_test65_1, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes65_2 = (model.predict(x_test65_2, verbose=1) > 0.5).astype("int32")[:,1]
predicted_classes65_3 = (model.predict(x_test65_3, verbose=1) > 0.5).astype("int32")[:,1]

for i in range(len(x_test65_1)):
 print("tcas65 รอบที่ 1 =%s, Predicted=%s" % (listtcas65_1[i], predicted_classes65_1[i]))

for i in range(len(x_test65_2)):
 print("tcas65 รอบที่ 2 =%s, Predicted=%s" % (listtcas65_2[i], predicted_classes65_2[i]))

for i in range(len(x_test65_3)):
 print("tcas65 รอบที่ 3 =%s, Predicted=%s" % (listtcas65_3[i], predicted_classes65_3[i]))

"""#Summary Predict

TCAS61
"""

pos_61_1, pos_61_2, pos_61_3, pos_61_4, pos_61_5 = 0,0,0,0,0
neg61_1, neg61_2, neg61_3, neg61_4, neg61_5 = 0,0,0,0,0

for i in range(len(predicted_classes61_1)):
  if predicted_classes61_1[i] == 0:
    neg61_1 += 1
  else: pos_61_1 += 1

for i in range(len(predicted_classes61_2)):
  if predicted_classes61_2[i] == 0:
    neg61_2 += 1
  else: pos_61_2 += 1

for i in range(len(predicted_classes61_3)):
  if predicted_classes61_3[i] == 0:
    neg61_3 += 1
  else: pos_61_3 += 1

for i in range(len(predicted_classes61_4)):
  if predicted_classes61_4[i] == 0:
    neg61_4 += 1
  else: pos_61_4 += 1

for i in range(len(predicted_classes61_5)):
  if predicted_classes61_5[i] == 0:
    neg61_5 += 1
  else: pos_61_5 += 1

"""TCAS62"""

pos_62_1, pos_62_2, pos_62_3, pos_62_4, pos_62_5 = 0,0,0,0,0
neg62_1, neg62_2, neg62_3, neg62_4, neg62_5 = 0,0,0,0,0

for i in range(len(predicted_classes62_1)):
  if predicted_classes62_1[i] == 0:
    neg62_1 += 1
  else: pos_62_1 += 1

for i in range(len(predicted_classes62_2)):
  if predicted_classes62_2[i] == 0:
    neg62_2 += 1
  else: pos_62_2 += 1

for i in range(len(predicted_classes62_3)):
  if predicted_classes62_3[i] == 0:
    neg62_3 += 1
  else: pos_62_3 += 1

for i in range(len(predicted_classes62_4)):
  if predicted_classes62_4[i] == 0:
    neg62_4 += 1
  else: pos_62_4 += 1

for i in range(len(predicted_classes62_5)):
  if predicted_classes62_5[i] == 0:
    neg62_5 += 1
  else: pos_62_5 += 1

"""TCAS63"""

pos_63_1, pos_63_2, pos_63_3, pos_63_4 = 0,0,0,0
neg63_1, neg63_2, neg63_3, neg63_4 = 0,0,0,0

for i in range(len(predicted_classes63_1)):
  if predicted_classes63_1[i] == 0:
    neg63_1 += 1
  else: pos_63_1 += 1

for i in range(len(predicted_classes63_2)):
  if predicted_classes63_2[i] == 0:
    neg63_2 += 1
  else: pos_63_2 += 1

for i in range(len(predicted_classes63_3)):
  if predicted_classes63_3[i] == 0:
    neg63_3 += 1
  else: pos_63_3 += 1

for i in range(len(predicted_classes63_4)):
  if predicted_classes63_4[i] == 0:
    neg63_4 += 1
  else: pos_63_4 += 1

"""TCAS64"""

pos_64_2, pos_64_3 = 0,0
neg64_2, neg64_3 = 0,0

for i in range(len(predicted_classes64_2)):
  if predicted_classes64_2[i] == 0:
    neg64_2 += 1
  else: pos_64_2 += 1

for i in range(len(predicted_classes64_3)):
  if predicted_classes64_3[i] == 0:
    neg64_3 += 1
  else: pos_64_3 += 1

"""TCAS65"""

pos_65_1, pos_65_2, pos_65_3 = 0,0,0
neg65_1, neg65_2, neg65_3 = 0,0,0

for i in range(len(predicted_classes65_1)):
  if predicted_classes65_1[i] == 0:
    neg65_1 += 1
  else: pos_65_1 += 1

for i in range(len(predicted_classes65_2)):
  if predicted_classes65_2[i] == 0:
    neg65_2 += 1
  else: pos_65_2 += 1

for i in range(len(predicted_classes65_3)):
  if predicted_classes65_3[i] == 0:
    neg65_3 += 1
  else: pos_65_3 += 1

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS61R1','TCAS61R2','TCAS61R3','TCAS61R4','TCAS61R5']
Pos = [pos_61_1,pos_61_2,pos_61_3,pos_61_4,pos_61_5]
Neg = [neg61_1,neg61_2,neg61_3,neg61_4,neg61_5]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Neg, width, label='Negsitive')
rects2 = ax.bar(x + width/2, Pos, width, label='Positive')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Count')
ax.set_title('Positive VS Negative 61')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS62R1','TCAS62R2','TCAS62R3','TCAS62R4','TCAS62R5']
Pos = [pos_62_1,pos_62_2,pos_62_3,pos_62_4,pos_62_5]
Neg = [neg62_1,neg62_2,neg62_3,neg62_4,neg62_5]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Neg, width, label='Negsitive')
rects2 = ax.bar(x + width/2, Pos, width, label='Positive')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Count')
ax.set_title('Positive VS Negative 62')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS63R1','TCAS63R2','TCAS63R3','TCAS63R4']
Pos = [pos_63_1,pos_63_2,pos_63_3,pos_63_4]
Neg = [neg63_1,neg63_2,neg63_3,neg63_4]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Neg, width, label='Negsitive')
rects2 = ax.bar(x + width/2, Pos, width, label='Positive')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Count')
ax.set_title('Positive VS Negative 63')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS63R2','TCAS63R3']
Pos = [pos_64_2,pos_64_3]
Neg = [neg64_2,neg64_3]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Neg, width, label='Negsitive')
rects2 = ax.bar(x + width/2, Pos, width, label='Positive')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Count')
ax.set_title('Positive VS Negative 64')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()

import matplotlib.pyplot as plt
import numpy as np


labels = ['TCAS63R1','TCAS63R2','TCAS63R3']
Pos = [pos_65_1,pos_65_2,pos_65_3]
Neg = [neg65_1,neg65_2,neg65_3]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, Neg, width, label='Negsitive')
rects2 = ax.bar(x + width/2, Pos, width, label='Positive')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Count')
ax.set_title('Positive VS Negative 65')
ax.set_xticks(x, labels)
ax.legend()

ax.bar_label(rects1, padding=3)
ax.bar_label(rects2, padding=3)

# fig.tight_layout()
fig.set_size_inches(20, 10)

plt.show()